\section{Collision Avoidance}
Collision avoidance is one of the fundamental problem in robotics. It is defined as a plan of action the robot should take to avoid a detected collision in the near future. This also means that there is no need to avoid collisions in case there are no oncoming collisions which gives rise to sub problem called collision detection. There is no collision avoidance without an appropriate collision detection mechanism running. This simple subconscious mechanism to be aware of the obstacles to avoid unintended contact with the environment in human beings are pretty complicated to automatize in robots. Though collisions are handled in the planning level, the complications arise when un-modeled obstacles appeared in the environment or an obstacle is moving in the environment. The robot should continuously performs the sense-act cycle applying an appropriate collision avoidance algorithm based on the instantaneous local observations of the world to be free of collisions while executing a goal. 

The main motivation behind collision avoidance is ensure safety of the robots, its connected components and most importantly the interaction with the human beings and the environment. The curse of putting robots inside the cage has been already pointed out in the previous section to ensure the maximum safety. Also, the other motivation is to have a robot control to focus on finishing the tasks efficiently and naturally by avoiding unintended contacts with the environment during the progress. Avoiding collisions is not necessarily the only way to ensure safety. Avoiding collisions or contact with the environment is an extrinsic robot behavior which requires constant computation of the robot (and its connected parts) with respect to the environment while there are intrinsic robot interaction which measures the impact forces to be compliant with the environment. This constrains the speed of the working speed of the robot and doesn't effectively utilize the potential of the robot. Both kinds of interaction are quite relevant to our proposed framework as it involves both skin sensors and 3d depth information to avoid collisions.
% [TO BE REWRITTEN]
The algorithm to avoid obstacles depends has to consider a variety of factors. The first and foremost factor is the capability of the robot and the interaction with the environment. Though collision avoidance is generally defined in the context of autonomous mobile robot navigation, it is quite relevant to manipulators, mobile manipulators, humanoids and all other kind of robots. The mobile navigation has very few degrees of freedom to be controlled whereas redundant systems have multiple degrees of freedom to be controlled which makes collision avoidance 3 dimensional space complex. This complexity usually comes with a computational cost affecting the efficiency of the algorithms. The control/planning algorithm should also be able to utilize the robot's capabilities effectively during the run time. The second factor is the ability to detect instantaneous collisions in run time. This depends both on the perception of the environment through the sensors and the sensor data interpretation to detect collisions. There are different ways to perceive an environment: Laser scans for 2d navigation, Point cloud information for 3d collision avoidance, etc. In our proposed framework in this thesis uses infrared sensors in the skin to measure proximity information. Though the sensor accuracy and update rate in the recent technologies are quite matured, it cannot be denied that there are no difficulties to collision avoidance. The solutions usually has to make a trade-off with the robot behaviors with the available sensors in the setup. 
\label{sec:ca}
\subsection{State of the Art}
The collision avoidance problem has been researched extensively since the 1980s resulting in a variety of methodologies avoiding the collisions either in the planning or in the controller level of the robot. The very first real time collision avoidance component was introduced in \cite{khatib1986real} based on potential field which occupy the majority of the real time collision avoidance algorithms today. Control laws based on artificial attractive and repulsive fields (depending on the distance between the robot and the obstacles/goals) are created to execute a collision free and a goal oriented motion. The insight to generate successful motions in dynamically changing environments by applying both the global information of the  planner and local obstacle constraints has resulted in a variety of real-time adaptive motion planning methods. They usually generate parametrized planned paths which is modulated during the run time depending on its interaction with the environment to ensure safety \cite{lindemann2005current,brock2008manipulation}. In \cite{warren1989global}, potential functions are used in global planning to avoid local minima by defining potential functions of the robot interactions with the obstacles in the configuration space. The linear path connecting the start and the final state is exposed to the artificial field resulting in incremental deformation to avoid collisions during the trajectory execution. The approach is not generic and flexible as defining potential functions becomes very difficult with higher degrees of freedom. 

A similar approach was proposed in \cite{quinlan1993elastic} with planned path represented as a curve in configuration space with properties of an elastic band. The obstacles have a repulsive action with the trajectories elongating like an elastic band thus avoiding the obstacles. The main difference is that the proximity information from the workspace modulates the path compared to representation of obstacles in the configuration space making the latter efficient. But the efficiency decreases with the increase in the degrees of freedom and the geometrical complexity. Also the real time performance is affected because of the conservative nature of the estimate making it less agile.  \cite{baginski1998motion} proposes a fast motion planning algorithm called the BB method which literally means 'Blow up the robot and Bend the trajectory'. The algorithm basically reshapes the path to generate collision free path by reducing the dimensions of the robot and then repositions the conflicting joints incrementally to let the complete robot pass. But still it suffers from local minima and it cannot incorporate local motion constraints in the run time. A much more generic and efficient framework called Elastic Strip in \cite{brock2002elastic} which integrates global motion planning and a task-based control with reactive obstacle avoidance. Obstacle avoidance as an inequality constraint in the control law was primarily introduced in \cite{Faverjon1987} which is extended in \cite{Kanehiro-RSS08} to handle not necessarily convex polyhedral objects by managing the continuity of the constraints using Voronoi regions of polyhedral faces.  In \cite{ogren2000reactive}, coordinated motions between the base and arm are generated to achieve an end-effector goal while avoiding the obstacles encountered by the base.

In \cite{vannoy2008real}, splines are generated to represent planned trajectories with collision free knots or waypoints generated by the planner whereas a roadmap is used in case of \cite{yang2006elastic,brock2001decomposition}. During the runtime, the planned path is modified by adjusting to the detected obstacles. In \cite{balan2006real}, the robot and the obstacles are modeled as spherical objects to generate a collision free trajectory by searching in the space of end-effector in predefined directions. A hybrid method which uses both potential and circular fields to model the interaction between the robot and the complex environment is presented in \cite{haddadin2011dynamic}. \cite{haddadin2010real} used virtual spring and dampers in the workspace to generate collision free trajectories using a impedance controller. All the above methodologies assume the availability of the distance between robot and the environment to create virtual fields. The first attempt to measure the distance from a 2D image was proposed in \cite{kuhn2007fast}. The minimum distance between collision bodies is computed by   
expanding the convex hull of the robot until it collides with the recorded image. Though the closest points cannot be known, the distance vector was sufficient to avoid collision. In the last decade, the usage of visual sensors with depth information has become essential to develop a 3d collision avoidance system for robotic arms though laser scanners are sufficient for mobile robot bases. Microsoft Kinect is one such low-cost depth sensor which can record 3d information helpful to measure distance between objects. The depth information is projected in the robot-centric space and approximate representations of obstacles are built to measure the distance information for collision avoidance.

Depth data based collision avoidance implementations are quite a few and it is relevant to reactive path planning used in our proposed framework. In \cite{bascetta2010anti}, two approaches to avoid collisions in the cartesian space using laser sensor preserving time and geometrical properties of trajectories respectively. In \cite{schiavi2009integration}, both active collision avoidance and passive impedance control in the configuration space to improve the safety of the robot. \cite{Flacco2012} uses a classic potential field method to generate repulsive commands to avoid robot collisions in KUKA LWR IV arm in dynamic environment. A concept of depth space in proposed to evaluate distances between the robot and the obstacles with estimated velocities from 3d sensors. A generic motion task is executed with a control law fed by these virtual force vectors from the distance and velocities measured instantaneously. \cite{yang2010elastic} presented a solution based on elastic roadmap \cite{yang2006elastic} claiming to generate robust and task-consistent motions for redundant robots but not completely verified experimentally. \cite{pan2013real} proposes a real time collision detection and distance query algorithm efficient in handling huge amounts of point cloud information. Though the algorithm is developed, there is no record of complete experimental verification and the software is unavailable.

In the reactive control level of the our proposed framework, we use infrared ranges sensors in skin cells to measure proximity distance. The main advantage of using such sensors is the simplicity in measuring the distance directly rather than computing it after a lot of preprocessing which is usually the case with point cloud information. Majority of the collision avoidance methods with haptic skin sensors are intrinsic with reacting to impacts after a contact is made with the obstacle by quantifying the applied force on the robot \cite{haddadin2008collision,de2004adapt,de2006collision,phan2011capacitive}. Extensive research has aimed to quantify the potential for personal injury from robot-human collisions (Haddadin et al. 2011). Research has been done to find out safe joint velocities with relevance to injuries caused by robot-human collisions\cite{haddadin2011dynamic,haddadin2012truly}. The latest work \cite{Killpack2016} uses an impact-momentum model in the objective function to regulate joint velocities specifically to reduce the impact forces from unexpected obstacles.

% trajectory generation
% These way points can also be processed using a trajectory generator which can handle the interactions with the obstacles leading to a good symbiosis. Based on this idea, we can realize robotic systems which can move according to global and task-dependent motion planning and do not loose the ability to instantaneously react to low-level sensor

% \subsection{Remarks}
% Since a 6-axis robot was designed at Stanford allowing a systematic way to design a robot and compute inverse kinematic solution analytically in the seventies, robots have been widely used for a variety of applications from punching cards and palletizing food items to assembly , welding in big automobile manufacturing lines and intelligent stock handling in warehouses \cite{scheinman1969design}. Safety and reliability became a significantly potential area of research since then \cite{dhillon2012robot}. These robots are usually installed in closed chambers, fixed on the ground and absolute care is taken not to make it operational when the door is open or when the co-worker is around the robot’s workspace {safetyreqs}. The safety guidelines are obviously strict as it is crucial to avoid humans in danger. But things are changing quite rapidly and we have an increased focus on human-robot collaboration with enhanced safety in the last decade \cite{Bicchi2008,dhillon2012robot} driven by creative industrial demands and high interest in flexible mobile manipulators. The safety is evaluated based on various factors influencing the human-robot collision impact such as the proximity distance, relative velocity, robot inertia and so on \cite{Kulic2006}. One of the main requirement is the robot’s capability to perceive the environment and react to it.


% Collision avoidance is an essential functionality in terms of safety and it is a well researched topic with various approaches  to handle different scenarios. In the earlier times, the approaches model the obstacles as static entities treating them as a planning problem to avoid collisions \cite{van2011reciprocal}. Replanning is performed based on instantaneous observations if the obstacles are dynamic. These planning based approaches limit the low level control to simple operations with controller frequencies  several times smaller than robot-environment iteration time. Constrained based approaches focus on enhancing low level control to perform complex operations by taking sensor data directly to be reactive enough with the environment \cite{khatib1986real}. The Collision avoidance can be modeled as inequality constraints or tasks in an optimization based controller. There are a variety of possible inequalities both in robot and environment in robot application scenarios. Some examples are joint limits, singularity avoidance, and object tracking in visual servoing. Constraint based robot programming were used extensively to resolve these constraints  locally but were specific to robot and the scenario involved.
